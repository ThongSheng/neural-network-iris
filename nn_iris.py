# -*- coding: utf-8 -*-
"""Simple Neural Network on Iris

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WpDKBcko_2N5mUz4IbS20L30rjDIc9iR
"""

# Commented out IPython magic to ensure Python compatibility.
import torch
import torch.nn as nn
import torch.nn.functional as F

import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline

# Create a Model Class that inherits nn.Module
class Model(nn.Module):

  # Input layer (4 features of the iris dataset) --> hidden layers (2 layers with 8 and 9 neurons each (arbituary)) --> output (predict the 3 classes of iris flowers)
  def __init__(self, in_features = 4, h1 = 8, h2 = 9, out_features = 3):
    super().__init__() # Instanstiate nn.Module
    self.fc1 = nn.Linear(in_features, h1)
    self.fc2 = nn.Linear(h1, h2)
    self.out = nn.Linear(h2, out_features)

  # Use RELU to push the neural network forward
  def forward(self, x):
    x = F.relu(self.fc1(x))
    x = F.relu(self.fc2(x))
    x = self.out(x)

    return x

# Create instance of model
torch.manual_seed(123)
model = Model()

# Read in data
url = 'https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv'
df = pd.read_csv(url)
df.head()

# Changing last column from strings to numbers
mapping = {'Setosa': 0, 'Versicolor': 1, 'Virginica': 2}
df['variety'] = df['variety'].map(mapping)
df.head()

# Assign X and y and convert them to numpy arrays
X = df.drop('variety', axis=1).values
y = df['variety'].values

# Train test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)

# Convert X into float tensors
X_train = torch.FloatTensor(X_train)
X_test = torch.FloatTensor(X_test)

# Convert y into long tensors (integers)
y_train = torch.LongTensor(y_train)
y_test = torch.LongTensor(y_test)

# Set the criterion of model to measure the error
criterion = nn.CrossEntropyLoss() # Cross Entropy Loss is useful when you have unbalanced training set

# Choose Adam optimizer and set learning rate
optimizer = torch.optim.Adam(model.parameters(), lr = 0.01) # lower learning rate = longer training time
#print(model.parameters)

# Train model
epochs = 200
losses =[]

for i in range(epochs):
  # Go forward and get a prediction
  y_pred = model.forward(X_train)

  # Measure store the loss (will be high at first)
  loss = criterion(y_pred, y_train)
  losses.append(loss.detach().numpy())

  # Print every 10 epoch
  if i % 10 == 0:
    print(f'Epoch: {i} and loss: {loss}')

  # Backpropagation (use error rate from forward propagation and feed it thru the network to fine tune the weights)
  optimizer.zero_grad()
  loss.backward()
  optimizer.step()

# Visualize loss
plt.plot(range(epochs), losses)
plt.ylabel("Loss/Error")
plt.xlabel("Epoch")

# Evaluate on test data set
with torch.no_grad(): # Basically turn off back propagation
  y_eval = model.forward(X_test)
  loss = criterion(y_eval, y_test)

print(loss)

# Print test results
correct = 0

# Print header and a separator line
print(f"{'Sample':<10} | {'Likelihood':<40} | {'Predicted Class':<15} | {'True Class':<15}")
print("-" * 85)

with torch.no_grad():
  for i, data in enumerate(X_test):
    y_val = model.forward(data)

    # For each data, print which outcome is most likely (i.e. higher value in 1st row = higher likelihood the flower is Setosa)
    print(f'{i+1:<10} | {str(y_val):<40} | {y_val.argmax().item():<15} | {y_test[i]:<15}')

    # Count # of correct predictions
    if y_val.argmax().item() == y_test[i]:
      correct += 1

print(f'We got {correct} correct!')

# Predict new data
new_iris = torch.tensor([4.7, 3.2, 1.3, 0.2])

with torch.no_grad():
  prediction = model(new_iris).argmax().item()
  if prediction == 0:
    print("Setosa")
  elif prediction == 1:
    print("Versicolor")
  else:
    print("Virginica")

# Save NN model with trained parameters
torch.save(model.state_dict(), "iris_nn_model.pt")

# Load saved NN model
new_model = Model()
new_model.load_state_dict(torch.load("iris_nn_model.pt"))

# Verify model is loaded correctly
new_model.eval()

# Predict "new_iris" with loaded model
with torch.no_grad():
  prediction_new_model = new_model(new_iris).argmax().item() # new_model is used instead of model
  if prediction_new_model == 0:
    print("Setosa")
  elif prediction_new_model == 1:
    print("Versicolor")
  else:
    print("Virginica")